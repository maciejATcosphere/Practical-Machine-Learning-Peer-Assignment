Weight Lifting Sensor Data Analysis
===================================

FIXME: USe parallelization to run random forest on all cores!
FIXME: say something about varImp variable importance
FIXME: It will make it easier for the graders if you submit a repo with a gh-pages branch so the HTML page can be viewed online
FIXME: Do the authors describe what they expect the out of sample error to be and estimate the error appropriately with cross-validation?
FIXME: Uncomment code for model building
FIXME: Justify more the choice of getting rid of low variance variables (maybe chart)?

You should create a report describing how you built your model, 
how you used cross validation, 
what you think the expected out of sample error is, 
and why you made the choices you did

FIXME -> TEMP
```{r}
setwd('/home/maciej/learning/Coursera/Machine-Learning/Assignment/')
```

```{r}
set.seed(3885)
library(caret)
library(doMC)
```

In order to leverage parallel execution, and therefore decrease the execution time, we use multicore package which if registerd
would be used by **train** to load balance the work on multiple workers (in our case 4). 
```{r}
registerDoMC(cores = 4)
```

## Exploratory Data Analysis

We read in **training.csv** file that will serve as a basis of our analysis. Then we split it to proper training and testing
set that would be used to model fitting and model evaluation respectively.
```{r}
data <- read.csv('data/training.csv')
submission_data <- read.csv('data/testing.csv')

inTrain <- createDataPartition(y=data$classe, p=0.6, list=FALSE)
training <- data[inTrain,]
testing <- data[-inTrain,]
```
We noticed that the data set contains verbose column **X** which contains all unique values (probably being an index that was saved by the creators of the data set) enumerating rows. We can freely drop this column since it would not add anything to our analysis. 
Exclude X column
```{r}
data <- data[,-c(1)]
```
Further one can take a look at the original data set and just to measure how well the **classe** variable is spread among sample data.
```{r fig.width=7, fig.height=6}
classe_dict <- aggregate(raw_timestamp_part_1 ~ classe, data=data, FUN=length)
barplot(classe_dict$raw_timestamp_part_1, names.arg=classe_dict$classe)
title("Distribution of classe")
```

Since we deal with quite a big amount of features (columns) one can drop those that contains large amount of **NAs**. We decided to go with arbiterly chosen value 0.03 which serve as a threshold for dropping the almost empty columns:
```{r}
not.na <- apply(training, 2 , function (col) { 1 - sum(is.na(col)) / nrow(training) }) > 0.03
training <- training[, not.na]
```

Futhermore we can get rid of few more coulmns by simply selecting those with extremly low variablity:
```{r}
nzv <- nearZeroVar(training, saveMetrics=TRUE)
exclude_nzv <- rownames(subset(nzv, nzv == TRUE))
training <- training[ , -which(names(training) %in% exclude_nzv)]
```

# FIXME: Try to understand impact of some of the variables on the final classification

## Training

After we quick exploration with regards to the type of model to be used during the training we decided to go with random forest. 

We tried simple decision tree but it's initial results were far from satisfactory. Additionally we gave a try to boosting algorithm but it failed due to memory error. 

By default random forest model will use bootstrapping with 25 samples which is more than enough to assure decent cross validation during the training set. 

As one can the accuracy of the fitted model on the training set is inredible high: FIXME!!!

```{r cache=TRUE}
#modFit <- train(classe ~ ., data=training, method='rf')
#modFit
```

## Evaluation

We measure a performance of our predictive model on the hold-out set (part of the initial data). As one can see the final accuracy on the testing set is very high: FIXME!!!. 
```{r}
#predictions <- predict(modFit, newdata=testing)
#confusionMatrix(predictions, testing$classe)
```

## Submission

As a final step we generate submission files:
```{r}
#answers <- predict(modFit, newdata=submission_data)
#pml_write_files = function(x){
#    n = length(x)
#    for(i in 1:n){
#        filename = paste0("./answers/problem_id_",i,".txt")
#        write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
#    }
#}
#pml_write_files(answers)
```
